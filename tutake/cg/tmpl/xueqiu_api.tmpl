"""
This file is auto generator by CodeGenerator. Don't modify it directly, instead alter tushare_api.tmpl of it.

Xueqiu {{name}}接口
{{desc}}

@author: rmfish
"""
import pandas as pd
from sqlalchemy import Integer, String, Float, Boolean, Column, create_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import QueuePool

from tutake.api.base_dao import BaseDao, BatchWriter, TutakeTableBase
from tutake.api.process import DataProcess, ProcessException
from tutake.api.xq.{{name}}_ext import *
from tutake.api.xq.xueqiu_base import XueQiuBase
from tutake.utils.config import TutakeConfig
from tutake.utils.utils import project_root


class {{entity_name}}(TutakeTableBase):
    __tablename__ = "{{table_name}}"
    {% for output in outputs %}{{output.name}} = Column({{output.data_type|get_sql_type}}{% if output.primary_key %}, primary_key=True{% endif %}{% if output.index %}, index=True{% endif %}, comment='{% autoescape false %}{{output.desc}}{% endautoescape %}')
    {% endfor %}


class {{title_name}}(BaseDao, XueQiuBase, DataProcess):
    instance = None

    def __new__(cls, *args, **kwargs):
        if cls.instance is None:
            cls.instance = super().__new__(cls)
        return cls.instance

    def __init__(self, config):
        self.table_name = "{{table_name}}"
        self.database = '{{database}}.duckdb'
        self.database_dir = config.get_tutake_data_dir()
        self.database_url = config.get_data_driver_url(self.database)
        self.engine = create_engine(self.database_url, poolclass=QueuePool)
        session_factory = sessionmaker()
        session_factory.configure(bind=self.engine)
        {{entity_name}}.__table__.create(bind=self.engine, checkfirst=True)
        self.schema = BaseDao.parquet_schema({{entity_name}})

        query_fields = [{% for input in inputs %}'{{input.name}}'{% if not loop.last %}, {% endif %}{% endfor %}]
        entity_fields = [{% for output in outputs %}"{{output.name}}"{% if not loop.last %}, {% endif %}{% endfor %}]
        BaseDao.__init__(self, self.engine, session_factory, {{entity_name}}, self.database, self.table_name, query_fields, entity_fields, None, config)
        DataProcess.__init__(self,"{{name}}", config)
        XueQiuBase.__init__(self,"{{name}}", config)

    def columns_meta(self):
        return [{% for output in outputs %}{"name":"{{output.name}}","type":"{{output.data_type|get_sql_type}}","comment":"{% autoescape false %}{{output.desc}}{% endautoescape %}"}{% if not loop.last %},{% endif %}{% endfor %}]

    def {{name}}(self, fields='', **kwargs):
        """
        {{desc}}
        | Arguments:
        {% for input in inputs %}| {{input.name}}({{input.data_type}}): {% if input.must=='Y' %}required{% endif %}  {{input.desc}}
        {% endfor %}
        :return: DataFrame
        {% for output in outputs %} {{output.name}}({{output.data_type}})  {% autoescape false %}{{output.desc}}{% endautoescape %}
        {% endfor %}
        """
        return super().query(fields, **kwargs)

    def process(self, **kwargs):
        """
        同步历史数据
        :return:
        """
        return super()._process(self.fetch_and_append, BatchWriter(self.engine, self.table_name, self.schema, self.database_dir), **kwargs)

    def fetch_and_append(self, **kwargs):
        """
        获取tushare数据并append到数据库中
        :return: 数量行数
        """
        init_args = { {% for input in inputs %}"{{input.name}}": ""{% if not loop.last %},{% endif %}{% endfor %} }
        if len(kwargs.keys()) == 0:
            kwargs = init_args
        # 初始化offset和limit
        if not kwargs.get("limit"):
            kwargs['limit'] = self.default_limit()
        init_offset = 0
        offset = 0
        if kwargs.get('offset'):
            offset = int(kwargs['offset'])
            init_offset = offset

        kwargs = {
            key: kwargs[key] for key in kwargs.keys() & init_args.keys()
        }

        def fetch_save(offset_val=0):
            try:
                kwargs['offset'] = str(offset_val)
                self.logger.debug("Invoke pro.{{name}} with args: {}".format(kwargs))
                res = self.{{name}}_request(fields=self.entity_fields, **kwargs)
                res.to_sql('{{table_name}}', con=self.engine, if_exists='append', index=False, index_label=['ts_code'])
                return res
            except Exception as err:
                raise ProcessException(kwargs, err)

        df = fetch_save(offset)
        offset += df.shape[0]
        while kwargs['limit'] != "" and str(df.shape[0]) == kwargs['limit']:
            df = fetch_save(offset)
            offset += df.shape[0]
        return offset - init_offset

setattr({{title_name}}, 'default_limit', default_limit_ext)
setattr({{title_name}}, 'default_cron_express', default_cron_express_ext)
setattr({{title_name}}, 'default_order_by', default_order_by_ext)
setattr({{title_name}}, 'prepare', prepare_ext)
setattr({{title_name}}, 'query_parameters', query_parameters_ext)
setattr({{title_name}}, 'param_loop_process', param_loop_process_ext)


if __name__ == '__main__':
    pd.set_option('display.max_columns', 50)  # 显示列数
    pd.set_option('display.width', 100)
    config = TutakeConfig(project_root())

    api = {{title_name}}(config)
    api.process()  # 同步增量数据
    print(api.{{name}}({% autoescape false %}{{default_query}}{% endautoescape %}))  # 数据查询接口

